---
layout: post
title: C4ADS Project
subtitle: Manipulating Large Datasets and Machine Learning with Positive-Unlabeled Data
comments: true
---

#### I had the opportunity to work with a team of data scientists on a project for the Center for Advanced Defense Studies(**C4ADS**)


Per their [website](https://c4ads.org/):

> **C4ADS** is a nonprofit organization dedicated to providing data-driven analysis and evidence-based reporting on global conflict and transnational security issues.
We use cutting-edge technologies to manage, integrate, and analyze disparate data from diverse languages, regions, and sources, incorporating our own field research from conflict zones and fragile states. We seek to engage with local and international audiences and produce compelling analysis on conflict and security issues. In doing so, we fill a critical gap left by traditional public sector and profit-driven institutions.

The project was over two months, and involved analyzing a large dataset of nearly 200 Gigabytes, then attempting to train a machine learning model to classify highly imbalanced classes.

This was an exciting project, but one that came with many challenges.

&nbsp;
&nbsp;
&nbsp;

## Getting Started

An issue my team and I ran into immediately was where to begin. This was a build-on project, so there were mountains of notebooks, scripts, subsets of data saved, and notes left by the previous teams to work on the project. The notes provided some guidance on what we should focus on, and resources that were useful to them, but there was a lot of information we wish we'd had. That insight would lead us to put a lot of emphasis on documentation, and providing a smooth transition for the next group when our time was over.

Aside from understanding what had been done, we also had to learn how to do it. This project required learning tools I hadn't spent much time with. It was all through Amazon Web Service (AWS) and the dataset was much larger than anything I had dealt with before. 

Because of this, my team and I had to become very familiar with AWS and Elastic Map Reduce (EMR). Since our usual data manipulation tools aren't feasible with this much data, we also had to learn PySpark in conjunction with AWS EMR to explore and manipulate the data.

&nbsp;
&nbsp;
&nbsp;

## Exploring the Data

There were challenges in the data. The dataset did not include a data dictionary, so it was difficult to get a handle of what some of the features represented. This wouldn't be an issue with creating the model, just intuiting whether it would be worthwhile to include. Also, the dataset was in a foreign language, so any exploration of text data had to be translated to get an understanding of what we were looking at.

&nbsp;
&nbsp;
&nbsp;

## Modeling

A challenge we faced when modeling was deciding which method was appropriate. Along with our dataset, we were given a subset of that dataset that they had positively-labeled. So we only had the positive data, and the unlabeled data to work with. 

There are several strategies you can employ when working with positive-unlabeled data: 


> Two-step technique: Identify reliable negatives, then use machine learning on the positive and reliable negatives

> Biased Learning: Also known as noisy negative. Consider the data as fully labeled, with all unlabeled considered negative, then train on that newly labeled dataset.

> Class Prior Incorporation: Modifies standard learning methods by applying the “selected completely at random” assumption, using the class prior.


For the time we had, I was able to attempt a Biased Learning solution on a subset of the data, with the hopes of creating a large enough sample of reliable negatives to use the Two-Step Technique with, but time did not allow it. Though, even with this simple model on a subset of the data, our team was able to identify likely-positives that prior groups hadn't detected.

&nbsp;
&nbsp;
&nbsp;

## Conclusion

This was an exciting project that presented a host of challenges to overcome. At the end of the day, we were able to present new findings, and a framework for future groups to build upon.

And while I'm happy with what we did, I'm more proud of what we left. Our team was able to provide a “Bible” of insights, a 20-page document for future groups to read upon entry that explains what the data is, how it was changed, and what we discovered. It also contains our estimation of a data-dictionary, and charts showing the flow of data, where and how it was transformed, and where it was saved.

Along with that document, we created a PySpark tutorial, including the most useful syntax we used throughout our time with the project. I also created a series of short, 5-minute video tutorials for creating clusters in AWS EMR, working with parquet files in AWS S3 buckets, and connecting to an AWS EC2 instance. My guiding principle was: “These insights and tutorials, while easy now, were an early roadblock for us, but they don't have to be for future groups.”
